{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "excel_file_path = 'D:\\DiveStats\\Carolina Sculti (1).xlsx'\n",
    "\n",
    "df = pd.read_excel(excel_file_path, header=[0, 1], index_col=0)\n",
    "\n",
    "df.columns = ['_'.join(col).strip() for col in df.columns.values]\n",
    "\n",
    "csv_file_path = 'diving_data.csv'\n",
    "\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"CSV file '{csv_file_path}' has been created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "excel_file_path = 'D:\\DiveStats\\Carolina Sculti (1).xlsx'\n",
    "\n",
    "df = pd.read_excel(excel_file_path, header=[0, 1], index_col=0, skiprows=[2, 3, 4, 5, 6, 7, 8])\n",
    "\n",
    "df.columns = ['_'.join(col).strip() for col in df.columns.values]\n",
    "\n",
    "df = df.dropna(how='all')\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "csv_file_path = 'diving_data_cleaned.csv'\n",
    "\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Cleaned CSV file '{csv_file_path}' has been created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "excel_file_path = 'Carolina Sculti (1).xlsx'\n",
    "df = pd.read_excel(excel_file_path, header=[0, 1], index_col=0)\n",
    "\n",
    "event_dfs = []\n",
    "\n",
    "for col in df.columns.levels[0].unique():\n",
    "    event_df = df[col]\n",
    "    event_df = event_df.dropna(how='all')    \n",
    "    event_df['Event'] = col    \n",
    "    event_dfs.append(event_df)\n",
    "\n",
    "final_df = pd.concat(event_dfs)\n",
    "final_df = final_df.reset_index()\n",
    "csv_file_path = 'diving_data_cleaned_new.csv'\n",
    "final_df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Cleaned CSV file '{csv_file_path}' has been created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# Your provided text data\n",
    "data = \"\"\"\n",
    "2023 USA Diving National Championships\n",
    "\n",
    "Senior Women 1m Springboard\n",
    "Diver: Sculti, Carolina - Crown Valley Divers (CVD)\n",
    "Place: 7\n",
    "Dive Number Height Description Net DD Score Round\n",
    "1 403B 1M Inward 1 1/2 Somersault Pike 20 2.40 48 8\n",
    "2 105B 1M Forward 2 1/2 Somersault Pike 16.50 2.60 42.90 13\n",
    "3 203B 1M Back 1 1/2 Somersault Pike 21 2.30 48.30 6\n",
    "4 303B 1M Reverse 1 1/2 Somersault Pike 19 2.40 45.60 8\n",
    "5 5333D 1M Reverse 1 1/2 Somersault 1 1/2 Twist Free 16 2.60 41.60 16\n",
    "Totals 92.50 12.30 226.40\n",
    "\n",
    "Senior Women 1m Springboard\n",
    "Diver: Sculti, Carolina - Crown Valley Divers (CVD)\n",
    "Place: 7\n",
    "Dive Number Height Description Net DD Score Round\n",
    "0 0M Carry Over from Previous Round 0 0 226.40 0\n",
    "1 403B 1M Inward 1 1/2 Somersault Pike 21 2.40 50.40 3\n",
    "2 105B 1M Forward 2 1/2 Somersault Pike 16.50 2.60 42.90 8\n",
    "3 203B 1M Back 1 1/2 Somersault Pike 20.50 2.30 47.15 4\n",
    "4 303B 1M Reverse 1 1/2 Somersault Pike 15 2.40 36 8\n",
    "5 5333D 1M Reverse 1 1/2 Somersault 1 1/2 Twist Free 19 2.60 49.40 4\n",
    "Totals 92 12.30 452.25\n",
    "\n",
    "# ... (paste the rest of the data here)\n",
    "\"\"\"\n",
    "\n",
    "# Convert the text data to a DataFrame\n",
    "df = pd.read_csv(StringIO(data), sep='\\t')\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('diving_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('diving_data_cleaned_new.csv')\n",
    "\n",
    "# Remove leading and trailing spaces from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Assuming the event information is in the first column, adjust this if needed\n",
    "event_data = df[df.iloc[:, 0].astype(str).str.contains('Senior Women 1m Springboard', na=False)]\n",
    "\n",
    "# Plot scores for each round\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Round', y='Score', data=event_data, hue='Diver')\n",
    "plt.title('Scores for Each Round - Senior Women 1m Springboard')\n",
    "plt.xlabel('Round')\n",
    "plt.ylabel('Score')\n",
    "plt.show()\n",
    "\n",
    "# Plot total scores for each diver\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Diver', y='Total Score', data=event_data)\n",
    "plt.title('Total Scores for Each Diver - Senior Women 1m Springboard')\n",
    "plt.xlabel('Diver')\n",
    "plt.ylabel('Total Score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('diving_data_cleaned_new.csv')\n",
    "\n",
    "# Print column names\n",
    "print(\"Column Names:\")\n",
    "print(df.columns)\n",
    "\n",
    "# Print a sample of the 'Round' column\n",
    "print(\"\\nSample of 'Round' Column:\")\n",
    "print(df['Round'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read data from CSV file\n",
    "df = pd.read_csv('diving_data.csv')\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming the first level is 'Carolina Sculti' and the second level is 'Senior Women 1m Springboard'\n",
    "# Adjust these based on your actual column levels\n",
    "level1 = 'Carolina Sculti'\n",
    "level2 = 'Senior Women 1m Springboard'\n",
    "\n",
    "# Visualization 1: Dive Scores Distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df[(level1, level2, 'Score')], bins=10, kde=True)\n",
    "plt.title('Distribution of Dive Scores')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Visualization 2: Dive Scores Boxplot by Round\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(x=(level1, level2), y=(level1, level2, 'Score'), data=df)\n",
    "plt.title('Dive Scores Boxplot by Round')\n",
    "plt.xlabel('Round')\n",
    "plt.ylabel('Score')\n",
    "plt.show()\n",
    "\n",
    "# Visualization 3: Dive Scores by Dive Type\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(x=(level1, level2), y=(level1, level2, 'Score'), data=df)\n",
    "plt.title('Average Dive Scores by Dive Type')\n",
    "plt.xlabel('Dive Type')\n",
    "plt.ylabel('Average Score')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'diving_data_cleaned.csv' with the actual file name after cleaning\n",
    "df = pd.read_csv('diving_data_cleaned.csv')\n",
    "\n",
    "# Display the first few rows and column names\n",
    "print(df.head())\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'diving_data_cleaned.csv' with the actual file name after cleaning\n",
    "df = pd.read_csv('diving_data_cleaned.csv', skiprows=2)\n",
    "\n",
    "# Define proper column names\n",
    "column_names = ['Description', 'Net', 'DD', 'Score', 'Round', 'Event', 'Diver', 'Place', 'NaN1', 'NaN2']\n",
    "\n",
    "# Set the column names and drop unnecessary columns\n",
    "df.columns = column_names\n",
    "df = df[['Description', 'Net', 'DD', 'Score', 'Round', 'Event', 'Diver', 'Place']]\n",
    "\n",
    "# Reset the index\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming the columns 'Diver', 'Round', and 'Score' are present in your DataFrame\n",
    "# Adjust these based on your actual column names\n",
    "diver_column = 'Diver'\n",
    "round_column = 'Round'\n",
    "score_column = 'Score'\n",
    "\n",
    "# Visualization 1: Dive Scores Distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df[score_column], bins=10, kde=True)\n",
    "plt.title('Distribution of Dive Scores')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Visualization 2: Dive Scores Boxplot by Round\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(x=round_column, y=score_column, data=df, hue=diver_column)\n",
    "plt.title('Dive Scores Boxplot by Round')\n",
    "plt.xlabel('Round')\n",
    "plt.ylabel('Score')\n",
    "plt.show()\n",
    "\n",
    "# Visualization 3: Dive Scores by Diver\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(x=diver_column, y=score_column, data=df)\n",
    "plt.title('Average Dive Scores by Diver')\n",
    "plt.xlabel('Diver')\n",
    "plt.ylabel('Average Score')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming the columns 'Diver', 'Round', 'Score', and 'Description' are present in your DataFrame\n",
    "# and you want to filter based on the selected values\n",
    "selected_values = ['401B', '301B', '107B', '205B', '5152B']\n",
    "\n",
    "# Filter DataFrame based on selected values in the 'Description' column\n",
    "filtered_df = df[df['Description'].isin(selected_values)]\n",
    "\n",
    "# Visualization 1: Dive Scores Distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(filtered_df['Score'], bins=10, kde=True)\n",
    "plt.title('Distribution of Dive Scores for Selected Dives')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Visualization 2: Dive Scores Boxplot by Round\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(x='Round', y='Score', data=filtered_df, hue='Diver')\n",
    "plt.title('Dive Scores Boxplot by Round for Selected Dives')\n",
    "plt.xlabel('Round')\n",
    "plt.ylabel('Score')\n",
    "plt.show()\n",
    "\n",
    "# Visualization 3: Dive Scores by Diver\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(x='Diver', y='Score', data=filtered_df)\n",
    "plt.title('Average Dive Scores by Diver for Selected Dives')\n",
    "plt.xlabel('Diver')\n",
    "plt.ylabel('Average Score')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_df)\n",
    "print(filtered_df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "url = \"https://diverecorder.co.uk/meetexplorer/diverevents.php?dref=3139\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    html_content = response.text\n",
    "\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Extracting data from the table\n",
    "    rows = soup.find_all('tr')\n",
    "\n",
    "    data = []\n",
    "    for row in rows:\n",
    "        columns = row.find_all('td')\n",
    "        row_data = [col.text.strip() for col in columns]\n",
    "        data.append(row_data)\n",
    "\n",
    "    # Save data to CSV\n",
    "    with open('scraped_data.csv', 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerows(data)\n",
    "\n",
    "    print(\"Data saved to 'scraped_data.csv'\")\n",
    "else:\n",
    "    print(\"Failed to retrieve the page. Status code:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import csv\n",
    "\n",
    "# url = \"https://diverecorder.co.uk/meetexplorer/diverevents.php?dref=3139\"  # Replace with the URL of your PHP page\n",
    "# response = requests.get(url)\n",
    "\n",
    "# if response.status_code == 200:\n",
    "#     html_content = response.text\n",
    "\n",
    "#     soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "#     # Find all ul elements with class \"selectblock\"\n",
    "#     ul_elements = soup.find_all('ul', class_='selectblock')\n",
    "\n",
    "#     for ul in ul_elements:\n",
    "#         # Extract data from each li within the current ul\n",
    "#         li_elements = ul.find_all('li')\n",
    "        \n",
    "#         data = []\n",
    "#         for li in li_elements:\n",
    "#             link = li.find('a')\n",
    "#             if link:\n",
    "#                 href = link['href']\n",
    "#                 text = link.text.strip()\n",
    "#                 data.append([text, href])\n",
    "\n",
    "#         # Save data to CSV for each ul\n",
    "#         if data:\n",
    "#             csv_filename = f'scraped_data_{ul_elements.index(ul) + 1}.csv'\n",
    "#             with open(csv_filename, 'w', newline='') as csvfile:\n",
    "#                 csv_writer = csv.writer(csvfile)\n",
    "#                 csv_writer.writerow(['Title', 'Link'])\n",
    "#                 csv_writer.writerows(data)\n",
    "\n",
    "#             print(f\"Data from ul {ul_elements.index(ul) + 1} saved to '{csv_filename}'\")\n",
    "# else:\n",
    "#     print(\"Failed to retrieve the page. Status code:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "def scrape_dive_sheet(url):\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        html_content = response.text\n",
    "\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Extract data from the dive sheet table\n",
    "        table = soup.find('table', class_='grid')\n",
    "        if table:\n",
    "            rows = table.find_all('tr')\n",
    "\n",
    "            data = []\n",
    "            for row in rows[1:]:  # Skip the header row\n",
    "                columns = row.find_all('td')\n",
    "                row_data = [col.text.strip() for col in columns]\n",
    "                data.append(row_data)\n",
    "\n",
    "            return data\n",
    "        else:\n",
    "            print(f\"No dive sheet table found on the page: {url}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def save_to_csv(data, csv_filename):\n",
    "    if data:\n",
    "        with open(csv_filename, 'w', newline='') as csvfile:\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "            csv_writer.writerows(data)\n",
    "        print(f\"Data saved to '{csv_filename}'\")\n",
    "\n",
    "# Example usage:\n",
    "base_url = \"https://diverecorder.co.uk/meetexplorer/diverevents.php?dref=3139\"  # Replace with the base URL of your PHP page\n",
    "links = [\n",
    "    \"/diversheet.php?mref=1155&eref=5&dref=3139&dref1=3139&dref2=0\",\n",
    "    \"/diversheet.php?mref=1155&eref=6&dref=3139&dref1=3139&dref2=0\",\n",
    "    \"/diversheet.php?mref=1155&eref=8&dref=3139&dref1=3294&dref2=3139\"\n",
    "]\n",
    "\n",
    "for link in links:\n",
    "    full_url = base_url + link\n",
    "    data = scrape_dive_sheet(full_url)\n",
    "\n",
    "    if data:\n",
    "        csv_filename = f'1_scraped_data_{links.index(link) + 1}.csv'\n",
    "        save_to_csv(data, csv_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "def scrape_and_save_data(player_url):\n",
    "    response = requests.get(player_url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        html_content = response.text\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Extract tournament name\n",
    "        tournament_name_element = soup.find('strong')\n",
    "        tournament_name = tournament_name_element.text.strip()\n",
    "\n",
    "        # Extract event details\n",
    "        event_details_elements = soup.find_all('h3')\n",
    "        for event_details_element in event_details_elements:\n",
    "            event_name_date = event_details_element.text.strip()\n",
    "\n",
    "            # Extract player name\n",
    "            player_name_element = event_details_element.find_next('p').find('strong')\n",
    "            player_name = player_name_element.text.strip()\n",
    "\n",
    "            # Extract table data\n",
    "            table = event_details_element.find_next('table', class_='grid')\n",
    "            rows = table.find_all('tr')\n",
    "\n",
    "            # Prepare data for CSV\n",
    "            data = []\n",
    "            header = [col.text.strip() for col in rows[0].find_all('td')]\n",
    "            data.append(header)\n",
    "\n",
    "            for row in rows[1:]:\n",
    "                columns = row.find_all('td')\n",
    "                row_data = [col.text.strip() for col in columns]\n",
    "                data.append(row_data)\n",
    "\n",
    "            # Save data to CSV\n",
    "            csv_filename = f\"{tournament_name}_{event_name_date}_{player_name}.csv\"\n",
    "            with open(csv_filename, 'w', newline='') as csvfile:\n",
    "                csv_writer = csv.writer(csvfile)\n",
    "                csv_writer.writerows(data)\n",
    "\n",
    "            print(f\"Data saved to {csv_filename}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "\n",
    "# Example usage\n",
    "player_url = \"https://diverecorder.co.uk/meetexplorer/diverevents.php?dref=3139\"\n",
    "scrape_and_save_data(player_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import csv\n",
    "\n",
    "class DivingSpider(scrapy.Spider):\n",
    "    name = 'diving_spider'\n",
    "    start_urls = ['https://diverecorder.co.uk/meetexplorer/diverevents.php?dref=3139']\n",
    "\n",
    "    def parse(self, response):\n",
    "        tournament_name = response.css('strong::text').get().strip()\n",
    "        print(f\"Tournament Name: {tournament_name}\")\n",
    "\n",
    "        event_blocks = response.css('ul.selectblock li a')\n",
    "        for event_block in event_blocks:\n",
    "            event_name = event_block.css('::text').get().strip()\n",
    "            event_link = event_block.css('::attr(href)').get()\n",
    "            print(f\"Event Name: {event_name}\")\n",
    "            \n",
    "            yield response.follow(event_link, self.parse_event, meta={'tournament_name': tournament_name, 'event_name': event_name})\n",
    "\n",
    "    def parse_event(self, response):\n",
    "        tournament_name = response.meta['tournament_name']\n",
    "        event_name = response.meta['event_name']\n",
    "        player_name = response.css('p strong::text').get().strip()\n",
    "        print(f\"Player Name: {player_name}\")\n",
    "\n",
    "        table_rows = response.css('table.grid tr')\n",
    "        header = [col.css('::text').get().strip() for col in table_rows[0].css('td')]\n",
    "        data = [header]\n",
    "\n",
    "        for row in table_rows[1:]:\n",
    "            row_data = [col.css('::text').get().strip() for col in row.css('td')]\n",
    "            data.append(row_data)\n",
    "\n",
    "        print(\"Data:\")\n",
    "        for row in data:\n",
    "            print(row)\n",
    "\n",
    "        csv_filename = f\"{tournament_name}_{event_name}_{player_name}.csv\"\n",
    "        print(f\"Data saved to {csv_filename}\")\n",
    "\n",
    "        # Save data to CSV\n",
    "        with open(csv_filename, 'w', newline='') as csvfile:\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "            csv_writer.writerows(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def clean_total(total_str):\n",
    "    # If the input is already a float, return it\n",
    "    if isinstance(total_str, float):\n",
    "        return total_str\n",
    "\n",
    "    # Remove non-numeric characters and convert to float\n",
    "    return float(''.join(c for c in str(total_str) if c.isdigit() or c in '.-'))\n",
    "\n",
    "def visualize_csv(csv_path):\n",
    "    # Load CSV data into a DataFrame with specified encoding\n",
    "    df = pd.read_csv(csv_path, encoding='latin1')\n",
    "\n",
    "    # Clean the 'Total' column\n",
    "    df['Total'] = df['Total'].apply(clean_total)\n",
    "\n",
    "    # Visualize Total Points\n",
    "    player_names = df['Dive'].astype(str).str.strip()\n",
    "    total_points = df['Total'].astype(float)\n",
    "\n",
    "    plt.bar(player_names, total_points)\n",
    "    plt.xlabel('Player')\n",
    "    plt.ylabel('Total Points')\n",
    "    plt.title(f'Total Points - {os.path.basename(csv_path)}')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def analyze_folder(folder_path):\n",
    "    # List all CSV files in the specified folder\n",
    "    csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "    # Visualize each CSV file in the folder\n",
    "    for csv_file in csv_files:\n",
    "        csv_path = os.path.join(folder_path, csv_file)\n",
    "        visualize_csv(csv_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = r'D:\\DiveStats\\diving_stats'\n",
    "    analyze_folder(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "def clean_total(total_str):\n",
    "    if isinstance(total_str, float):\n",
    "        return total_str\n",
    "    return float(''.join(c for c in str(total_str) if c.isdigit() or c in '.-'))\n",
    "\n",
    "def visualize_csv(csv_path):\n",
    "    df = pd.read_csv(csv_path, encoding='latin1')\n",
    "    df['Total'] = df['Total'].apply(clean_total)\n",
    "\n",
    "    player_names = df['Dive'].astype(str).str.strip()\n",
    "    total_points = df['Total'].astype(float)\n",
    "\n",
    "    plt.bar(player_names, total_points)\n",
    "    plt.xlabel('Player')\n",
    "    plt.ylabel('Total Points')\n",
    "    plt.title(f'Total Points - {os.path.basename(csv_path)}')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def analyze_folder(folder_path):\n",
    "    csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "    return csv_files\n",
    "\n",
    "folder_path = r'D:\\DiveStats\\diving_stats'\n",
    "csv_files = analyze_folder(folder_path)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    dcc.Dropdown(\n",
    "        id='csv-dropdown',\n",
    "        options=[{'label': file, 'value': file} for file in csv_files],\n",
    "        value=csv_files[0]\n",
    "    ),\n",
    "    dcc.Graph(id='csv-visualization')\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    Output('csv-visualization', 'figure'),\n",
    "    [Input('csv-dropdown', 'value')]\n",
    ")\n",
    "def update_graph(selected_csv):\n",
    "    csv_path = os.path.join(folder_path, selected_csv)\n",
    "    visualize_csv(csv_path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "def clean_total(total_str):\n",
    "    if isinstance(total_str, float):\n",
    "        return total_str\n",
    "    return float(''.join(c for c in str(total_str) if c.isdigit() or c in '.-'))\n",
    "\n",
    "def visualize_csv(csv_path):\n",
    "    df = pd.read_csv(csv_path, encoding='latin1')\n",
    "    df['Total'] = df['Total'].apply(clean_total)\n",
    "\n",
    "    fig = px.bar(df, x='Dive', y='Total', labels={'Dive': 'Player', 'Total': 'Total Points'},\n",
    "                 title=f'Total Points - {os.path.basename(csv_path)}')\n",
    "    fig.update_layout(xaxis_tickangle=-45, xaxis=dict(tickmode='array'))\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def analyze_folder(folder_path):\n",
    "    csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "    return csv_files\n",
    "\n",
    "folder_path = r'D:\\DiveStats\\diving_stats'\n",
    "csv_files = analyze_folder(folder_path)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    dcc.Dropdown(\n",
    "        id='csv-dropdown',\n",
    "        options=[{'label': file, 'value': file} for file in csv_files],\n",
    "        value=csv_files[0]\n",
    "    ),\n",
    "    dcc.Graph(id='csv-visualization')\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    Output('csv-visualization', 'figure'),\n",
    "    [Input('csv-dropdown', 'value')]\n",
    ")\n",
    "def update_graph(selected_csv):\n",
    "    csv_path = os.path.join(folder_path, selected_csv)\n",
    "    return visualize_csv(csv_path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "def clean_total(total_str):\n",
    "    if isinstance(total_str, float):\n",
    "        return total_str\n",
    "    return float(''.join(c for c in str(total_str) if c.isdigit() or c in '.-'))\n",
    "\n",
    "def visualize_csv(csv_path):\n",
    "    df = pd.read_csv(csv_path, encoding='latin1')\n",
    "    df['Total'] = df['Total'].apply(clean_total)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(df['Dive'], df['Total'], color='skyblue')\n",
    "    plt.xlabel('Total Points')\n",
    "    plt.ylabel('Player')\n",
    "    plt.title(f'Total Points - {os.path.basename(csv_path)}')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot to a BytesIO object\n",
    "    img = BytesIO()\n",
    "    plt.savefig(img, format='png')\n",
    "    img.seek(0)\n",
    "\n",
    "    # Encode the image to base64 for HTML display\n",
    "    encoded_img = base64.b64encode(img.getvalue()).decode()\n",
    "\n",
    "    return f'data:image/png;base64, {encoded_img}'\n",
    "\n",
    "def analyze_folder(folder_path):\n",
    "    csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "    return csv_files\n",
    "\n",
    "folder_path = r'D:\\DiveStats\\diving_stats'\n",
    "csv_files = analyze_folder(folder_path)\n",
    "\n",
    "# Visualize each CSV file in the folder\n",
    "for csv_file in csv_files:\n",
    "    csv_path = os.path.join(folder_path, csv_file)\n",
    "    img_path = visualize_csv(csv_path)\n",
    "    print(f'Visualizing: {csv_file}')\n",
    "    print(f'Image Path: {img_path}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
